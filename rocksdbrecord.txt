


enum FileType {
  kLogFile,
  kDBLockFile,
  kTableFile,
  kDescriptorFile,
  kCurrentFile,
  kTempFile,
  kInfoLogFile,  // Either the current one, or an old one
  kMetaDatabase,
  kIdentityFile,
  kOptionsFile,
  kBlobFile
};


enum RecordType {
  // Zero is reserved for preallocated files
  kZeroType = 0,
  kFullType = 1,

  // For fragments
  kFirstType = 2,
  kMiddleType = 3,
  kLastType = 4,

  // For recycled log files
  kRecyclableFullType = 5,
  kRecyclableFirstType = 6,
  kRecyclableMiddleType = 7,
  kRecyclableLastType = 8,
};

///////////////////////////////////////

Memory Table Options:

memtable_factory: The factory object of memtable. 
                  By specifying factory object user can change the underlying implementation of memtable, 
                  and provide implementation specific options.

write_buffer_size: Size of a single memtable.

db_write_buffer_size: Total size of memtables across column families. 
                      This can be used to manage the total memory used by memtables.

write_buffer_manager: Instead of specifying a total size of memtables, 
                    user can provide their own write buffer manager to control the overall memtable memory usage. 
                    Overrides db_write_buffer_size.

max_write_buffer_number: The maximum number of memtables build up in memory, before they flush to SST files.

allow_concurrent_memtable_write option: although only skiplist-based memtable supports the feature.

/////////////////////////////////////




/////////////////////////////////////
WAL options:
DBOptions::wal_dir:
             sets the directory where RocksDB stores write-ahead log files, 
            which allows WALs to be stored in a separate directory from the actual data.

DBOptions::WAL_ttl_seconds, DBOptions::WAL_size_limit_MB:
              these two fields affect how quickly archived WALs will be deleted. 
              Nonzero values indicate the time and disk space threshold to trigger archived WAL deletion. 
              See options.h for detailed explanation.

DBOptions::max_total_wal_size:
            In order to limit the size of WALs, RocksDB uses DBOptions::max_total_wal_size as the trigger of column family flush. 
            Once WALs exceed this size, RocksDB will start forcing the flush of column families to allow deletion of some oldest WALs. 
            This config can be useful when column families are updated at non-uniform frequencies. If there's no size limit, 
            users may need to keep really old WALs when the infrequently-updated column families hasn't flushed for a while.

DBOptions::avoid_flush_during_recovery

DBOptions::manual_wal_flush:
              DBOptions::manual_wal_flush determines whether WAL 
              flush will be automatic after every write or purely manual (user must invoke FlushWAL to trigger a WAL flush).
              the writes are keep in rocksdb buffer until FlushWAL


DBOptions::wal_filter:
          Through DBOptions::wal_filter, users can provide a filter object to be invoked while processing WALs during recovery. 
          Note: Not supported in ROCKSDB_LITE mode

WriteOptions::disableWAL:
        WriteOptions::disableWAL is useful when users rely on other logging or don't care about data loss.(myrocks)

WriteOptions.sync = true, the WAL file is fsync'ed before returning to the user.


If Options.recycle_log_file_num = false (the default). RocksDB always create new files for new WAL segments. 
                              Each WAL write will change both of data and size of the file, 
                              so every fsync will generate at least two I/Os, 
                              one for data and one for metadata. 
                              Note that RocksDB calls fallocate() to reserve enough space for the file, 
                              but it doesn't prevent the metadata I/O in fsync.

Options.recycle_log_file_num = true will keep a pool of WAL files and try to reuse them. 
                When writing to an existing log file, random writes are used from size 0. 
                Before writes hit the end of the file, the file size doesn't change, 
                so the I/O for metadata might be avoided (also depends on file system mount options). 
                Assuming most WAL files will have similar sizes, I/O needed for metadata will be minimal.



WAL Manager: log sequence number. log Writer/reader



/////////////////////////////////////


/////////////////////////////////////
WAL log format:
Log file consists of a sequence of variable length records. Records are grouped by kBlockSize. 
If a certain record cannot fit into the leftover space, 
then the leftover space is padded with empty (null) data. 
The writer writes and the reader reads in chunks of kBlockSize.

       +-----+-------------+--+----+----------+------+-- ... ----+
 File  | r0  |        r1   |P | r2 |    r3    |  r4  |           |
       +-----+-------------+--+----+----------+------+-- ... ----+
       <--- kBlockSize ------>|<-- kBlockSize ------>|

  rn = variable size records
  P = Padding
The log file contents are a sequence of 32KB blocks. The only exception is that the tail of the file may contain a partial block.


Record Format:
The record layout format is as shown below.

+---------+-----------+-----------+--- ... ---+
|CRC (4B) | Size (2B) | Type (1B) | Payload   |
+---------+-----------+-----------+--- ... ---+

CRC = 32bit hash computed over the payload using CRC
Size = Length of the payload data
Type = Type of record
       (kZeroType, kFullType, kFirstType, kLastType, kMiddleType )
       The type is used to group a bunch of records together to represent
       blocks that are larger than kBlockSize
Payload = Byte stream as long as specified by the payload size


/////////////////////////////////////


================================================================

Pipelined Write: WAL writes and memtable writes are sequential, and by making them run in parallel we can increase throughput. 
                 For one single writer WAL writes and memtable writes have to run sequentially. 
                 With concurrent writers, once the previous writer finishes its WAL write, 
                 the next writer waiting in the write queue can start writing to the WAL 
                 while the previous writer still has its memtable write ongoing. This is what pipelined writes do.

                 This increase concurrent by parallel writing WAL and writing memory table.

======================================================================


WriteBatch holds a collection of updates to apply atomically to a DB.
The updates are applied in the order in which they are added
to the WriteBatch.  For example, the value of "key" will be "v3"
after the following batch is written:
   batch.Put("key", "v1");
   batch.Delete("key");
   batch.Put("key", "v2");
   batch.Put("key", "v3");
Multiple threads can invoke const methods on a WriteBatch without
external synchronization, but if any of the threads may call a
non-const method, all threads accessing the same WriteBatch must use
external synchronization.




WriteBatch::rep_ :=
   sequence: fixed64
   count: fixed32
   data: record[count]
record :=
   kTypeValue varstring varstring
   kTypeDeletion varstring
   kTypeSingleDeletion varstring
   kTypeRangeDeletion varstring varstring
   kTypeMerge varstring varstring
   kTypeColumnFamilyValue varint32 varstring varstring
   kTypeColumnFamilyDeletion varint32 varstring
   kTypeColumnFamilySingleDeletion varint32 varstring
   kTypeColumnFamilyRangeDeletion varint32 varstring varstring
   kTypeColumnFamilyMerge varint32 varstring varstring
   kTypeBeginPrepareXID varstring
   kTypeEndPrepareXID
   kTypeCommitXID varstring
   kTypeRollbackXID varstring
   kTypeBeginPersistedPrepareXID varstring
   kTypeBeginUnprepareXID varstring
   kTypeNoop
varstring :=
   len: varint32
   data: uint8[len]


=====================================================================
Writer State: 

enum State : uint8_t {
    // The initial state of a writer.  This is a Writer that is
    // waiting in JoinBatchGroup.  This state can be left when another
    // thread informs the waiter that it has become a group leader
    // (-> STATE_GROUP_LEADER), when a leader that has chosen to be
    // non-parallel informs a follower that its writes have been committed
    // (-> STATE_COMPLETED), or when a leader that has chosen to perform
    // updates in parallel and needs this Writer to apply its batch (->
    // STATE_PARALLEL_FOLLOWER).
    STATE_INIT = 1,

    // The state used to inform a waiting Writer that it has become the
    // leader, and it should now build a write batch group.  Tricky:
    // this state is not used if newest_writer_ is empty when a writer
    // enqueues itself, because there is no need to wait (or even to
    // create the mutex and condvar used to wait) in that case.  This is
    // a terminal state unless the leader chooses to make this a parallel
    // batch, in which case the last parallel worker to finish will move
    // the leader to STATE_COMPLETED.
    STATE_GROUP_LEADER = 2,

    // The state used to inform a waiting writer that it has become the
    // leader of memtable writer group. The leader will either write
    // memtable for the whole group, or launch a parallel group write
    // to memtable by calling LaunchParallelMemTableWrite.
    STATE_MEMTABLE_WRITER_LEADER = 4,

    // The state used to inform a waiting writer that it has become a
    // parallel memtable writer. It can be the group leader who launch the
    // parallel writer group, or one of the followers. The writer should then
    // apply its batch to the memtable concurrently and call
    // CompleteParallelMemTableWriter.
    STATE_PARALLEL_MEMTABLE_WRITER = 8,

    // A follower whose writes have been applied, or a parallel leader
    // whose followers have all finished their work.  This is a terminal
    // state.
    STATE_COMPLETED = 16,

    // A state indicating that the thread may be waiting using StateMutex()
    // and StateCondVar()
    STATE_LOCKED_WAITING = 32,
  };


=======================================================================

// Tag numbers for serialized VersionEdit.  These numbers are written to
// disk and should not be changed.
enum Tag : uint32_t {
  kComparator = 1,
  kLogNumber = 2,
  kNextFileNumber = 3,
  kLastSequence = 4,
  kCompactPointer = 5,
  kDeletedFile = 6,
  kNewFile = 7,
  // 8 was used for large value refs
  kPrevLogNumber = 9,
  kMinLogNumberToKeep = 10,

  // these are new formats divergent from open source leveldb
  kNewFile2 = 100,
  kNewFile3 = 102,
  kNewFile4 = 103,      // 4th (the latest) format version of adding files
  kColumnFamily = 200,  // specify column family for version edit
  kColumnFamilyAdd = 201,
  kColumnFamilyDrop = 202,
  kMaxColumnFamily = 203,

  kInAtomicGroup = 300,
};



=======================================================================
# This is a RocksDB option file.
#
# For detailed file format spec, please refer to the example file
# in examples/rocksdb_option_file_example.ini
#

[Version]
  rocksdb_version=6.2.0
  options_file_version=1.1

[DBOptions]
  avoid_unnecessary_blocking_io=false
  two_write_queues=false
  allow_ingest_behind=false
  writable_file_max_buffer_size=1048576
  avoid_flush_during_shutdown=false
  avoid_flush_during_recovery=false
  info_log_level=DEBUG_LEVEL
  access_hint_on_compaction_start=NORMAL
  allow_concurrent_memtable_write=true
  enable_pipelined_write=false
  stats_dump_period_sec=600
  stats_persist_period_sec=600
  strict_bytes_per_sync=false
  WAL_ttl_seconds=0
  WAL_size_limit_MB=0
  max_subcompactions=1
  dump_malloc_stats=false
  db_log_dir=
  wal_recovery_mode=kPointInTimeRecovery
  log_file_time_to_roll=0
  enable_write_thread_adaptive_yield=true
  recycle_log_file_num=0
  table_cache_numshardbits=6
  atomic_flush=false
  preserve_deletes=false
  stats_history_buffer_size=1048576
  max_open_files=-1
  max_file_opening_threads=16
  delete_obsolete_files_period_micros=21600000000
  max_background_flushes=-1
  write_thread_slow_yield_usec=3
  base_background_compactions=-1
  manual_wal_flush=false
  wal_dir=/tmp/rocksdb_simple_example1
  max_background_compactions=-1
  bytes_per_sync=0
  max_background_jobs=16
  use_fsync=false
  unordered_write=false
  fail_if_options_file_error=false
  random_access_max_buffer_size=1048576
  compaction_readahead_size=0
  wal_bytes_per_sync=0
  new_table_reader_for_compaction_inputs=false
  skip_stats_update_on_db_open=false
  persist_stats_to_disk=false
  skip_log_error_on_recovery=false
  is_fd_close_on_exec=true
  use_adaptive_mutex=false
  error_if_exists=false
  write_thread_max_yield_usec=100
  enable_thread_tracking=false
  db_write_buffer_size=0
  create_missing_column_families=false
  paranoid_checks=true
  create_if_missing=true
  max_manifest_file_size=1073741824
  allow_2pc=false
  max_total_wal_size=0
  use_direct_io_for_flush_and_compaction=false
  manifest_preallocation_size=4194304
  use_direct_reads=false
  delayed_write_rate=16777216
  allow_fallocate=true
  keep_log_file_num=1000
  allow_mmap_reads=false
  max_log_file_size=0
  allow_mmap_writes=false
  advise_random_on_open=true
  

[CFOptions "default"]
  sample_for_compression=0
  compaction_pri=kMinOverlappingRatio
  merge_operator=nullptr
  compaction_filter_factory=nullptr
  memtable_factory=SkipListFactory
  memtable_insert_with_hint_prefix_extractor=nullptr
  comparator=leveldb.BytewiseComparator
  target_file_size_base=67108864
  max_sequential_skip_in_iterations=8
  compaction_style=kCompactionStyleLevel
  max_bytes_for_level_base=536870912
  bloom_locality=0
  write_buffer_size=134217728
  compression_per_level=kNoCompression:kNoCompression:kLZ4Compression:kLZ4Compression:kLZ4Compression:kLZ4Compression:kLZ4Compression
  memtable_huge_page_size=0
  max_successive_merges=0
  arena_block_size=16777216
  memtable_whole_key_filtering=false
  target_file_size_multiplier=1
  max_bytes_for_level_multiplier_additional=1:1:1:1:1:1:1
  snap_refresh_nanos=100000000
  num_levels=7
  min_write_buffer_number_to_merge=2
  max_write_buffer_number_to_maintain=0
  max_write_buffer_number=6
  compression=kSnappyCompression
  level0_stop_writes_trigger=36
  level0_slowdown_writes_trigger=20
  compaction_filter=nullptr
  level0_file_num_compaction_trigger=2
  max_compaction_bytes=1677721600
  compaction_options_universal={allow_trivial_move=false;stop_style=kCompactionStopStyleTotalSize;compression_size_percent=-1;max_size_amplification_percent=200;max_merge_width=4294967295;min_merge_width=2;size_ratio=1;}
  memtable_prefix_bloom_size_ratio=0.000000
  hard_pending_compaction_bytes_limit=274877906944
  ttl=0
  table_factory=BlockBasedTable
  soft_pending_compaction_bytes_limit=68719476736
  prefix_extractor=nullptr
  bottommost_compression=kDisableCompressionOption
  force_consistency_checks=false
  paranoid_file_checks=false
  compaction_options_fifo={allow_compaction=false;max_table_files_size=1073741824;}
  max_bytes_for_level_multiplier=10.000000
  optimize_filters_for_hits=false
  level_compaction_dynamic_level_bytes=false
  inplace_update_num_locks=10000
  inplace_update_support=false
  periodic_compaction_seconds=0
  disable_auto_compactions=false
  report_bg_io_stats=false
  
[TableOptions/BlockBasedTable "default"]
  pin_top_level_index_and_filter=true
  enable_index_compression=true
  read_amp_bytes_per_bit=8589934592
  format_version=2
  block_align=false
  metadata_block_size=4096
  block_size_deviation=10
  partition_filters=false
  block_size=4096
  index_block_restart_interval=1
  no_block_cache=false
  checksum=kCRC32c
  whole_key_filtering=true
  index_shortening=kShortenSeparators
  data_block_index_type=kDataBlockBinarySearch
  index_type=kBinarySearch
  verify_compression=false
  filter_policy=nullptr
  data_block_hash_table_util_ratio=0.750000
  pin_l0_filter_and_index_blocks_in_cache=false
  block_restart_interval=16
  cache_index_and_filter_blocks_with_high_priority=true
  cache_index_and_filter_blocks=false
  hash_index_allow_collision=true
  flush_block_policy_factory=FlushBlockBySizePolicyFactory
  